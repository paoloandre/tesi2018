\chapter{Scelta Tecnologica}
\label{chap:scelta}
In questo capitolo viene trattata l'architettura utilizzata per unicam-product-editor e il modo in cui vengono gestiti i dati attraverso la web app, per poi passare ad illustrare l'organizzazione del codice.

Per sviluppare unicam-product-editor è stato utilizzato lo stack MEAN che non è altro che l'insieme dei quattro componenti che ne fanno parte:
\begin{itemize}
	\item M = MongoDB: il popolare database
	\item E = Express.js: un framework web leggero
	\item A = Angular.js: un framework per la creazione di single page application
	\item N = Node.js v4: un interprete JavaScript costruito sul motore JavaScript V8 di Google Chrome orientato agli eventi che lo rende efficiente e leggero
\end{itemize}
Lo stack MEAN è un' alternativa al più tradizionale stack LAMP (Linux, Apache, MySQL, PHP/Perl/Python/P…), molto popolare per il suo utilizzo nella costruzione di applicazioni web dagli anni '90 in poi.
Di seguito andiamo a costruire le RESTful API\cite{restful_api}, che sono la base per qualsiasi tipo di applicazione, come un sito web, un'app Android, iOS o Ubuntu Touch.

\section{Oggetti 3D}
Un modello 3D è una rappresentazione matematica di un oggetto tridimensionale e consiste sostanzialmente in un file di dati strutturati, contenenti le proprietà delle primitive geometriche che costituiscono l'oggetto rappresentato (un corpo fisico). Un oggetto 3D quindi non è altro che un insieme di dati composto da punti nello spazio tridimensionale (tre dimensioni X, Y e Z) e altre informazioni (spesso metadati, o informazioni aggiuntive).
I principali formati utilizzati per i modelli 3D:
\begin{itemize}
	\item OBJ
	\item FBX
	\item Collada
	\item BLEND
	\item DFX
	\item STL
	\item PLY
	\item 3DS (obsoleto)
	\item VRML (obsoleto)
	\item X3D
\end{itemize}
La scelta per cui abbiamo optato per la realizzazione del nostro progetto è ricaduta sul .obj, o più correttamente Wavefront .obj, un formato di file sviluppato dalla Wavefront Technologies per il software Advanced Visualizer. Il motivo di questa scelta risiede nel fatto che il .obj è un formato aperto che è stato adottato da tantissimi applicativi per la grafica 3D per l'interscambio di dati con altri programmi; ciò lo rende perfetto per il nostro progetto, in quanto questo dovrà poi essere trasformato in un corrispondente file .JSON per poter essere interpretato dal viewer\cite{upv}.

Questo è, per intero, il file .obj per la creazione di un cubo

\begin{lstlisting}[caption={Cube.obj}, style=JavaScriptCode]
# cube.obj
#

g cube

v  0.0  0.0  0.0
v  0.0  0.0  1.0
v  0.0  1.0  0.0
v  0.0  1.0  1.0
v  1.0  0.0  0.0
v  1.0  0.0  1.0
v  1.0  1.0  0.0
v  1.0  1.0  1.0

vn  0.0  0.0  1.0
vn  0.0  0.0 -1.0
vn  0.0  1.0  0.0
vn  0.0 -1.0  0.0
vn  1.0  0.0  0.0
vn -1.0  0.0  0.0

f  1//2  7//2  5//2
f  1//2  3//2  7//2 
f  1//6  4//6  3//6 
f  1//6  2//6  4//6 
f  3//3  8//3  7//3 
f  3//3  4//3  8//3 
f  5//5  7//5  8//5 
f  5//5  8//5  6//5 
f  1//4  5//4  6//4 
f  1//4  6//4  2//4 
f  2//1  6//1  8//1 
f  2//1  8//1  4//1 
\end{lstlisting}
in cui sono specificate le posizioni e le grandezze nello spazio tridimensionale dei vertici (v), dei vertici normali (vn), e delle facce (f).

\newpage
L'oggetto 3D che ne deriva può essere facilmente visualizzato tramite ad esempio il programma Paint 3D:

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.35]{Immagini/cube_obj.png}
	\caption{Visualizzazione grafica di cube.obj}
\end{figure}

\section{JSON}
JSON è un formato di dati molto leggere basato su un sottoinsieme della sintassi JavaScript, cioè \emph{array literal} e \emph{object literal}, proposto da Douglas Crockford come formato per i servizi web in sostituzione al verboso XML.

Dato l'utilizzo della sintassi Javascript, le definizioni JSON\cite{json} possono essere incluse all'interno dei file JavaScript\cite{javascript}.
\subsection{Gli array literal}

Gli \emph{array literal} rappresentano il metodo più semplice per creare un array in JavaScript.
Basta infatti elencare una insieme di valori separati da una virgola all'interno delle parentesi quadre, per esempio:
\begin{lstlisting}[style=JavaScriptCode]
var users = ["Paolo", "Antonio", "Filippo"];
\end{lstlisting}
A livello di programmazione è equivalente al codice:
\begin{lstlisting}[style=JavaScriptCode]
var users = new Array("Paolo", "Antonio", "Filippo");
\end{lstlisting}
Entrambe le definizioni generano lo stesso risultato ed è possibile accedere ad ogni elemento dell'array utilizzando il relativo indice 
\begin{lstlisting}[style=JavaScriptCode]
console.log(users[0]); \\prints Paolo 
console.log(users[1]); \\prints Antonio
console.log(users[2]); \\prints Filippo
\end{lstlisting}
Gli array in JavaScript hanno però due caratteristiche ben precise:
\begin{enumerate}
	\item In JavaScript l'array non ha un tipo di dati ben definito (non è tipizzato), e quindi ogni elemento può contenere tipi di dati diversi.
	\item Nonostante entrambi i metodi sopra citati per la creazione di un array siano validi in JavaScript, in .JSON soltanto gli array literal verranno accettati e interpretati correttamente.
\end{enumerate}

\subsection{Gli object literal}
Un object literal è definito tra parentesi graffe.
Al suo interno troviamo un numero qualsiasi di coppie chiave-valore, definite con una stringa, i due punti ed il valore.
Ogni coppia deve essere seguita da una virgola, tranne l'ultima. 
Questo insieme di coppie chiave-valore rappresenta, nel suo insieme, un oggetto.
Un esempio:
\begin{lstlisting}[style=JavaScriptCode]
var user = {
"firstname": "Paolo",
"age": 23,
"student": true
};
\end{lstlisting}
Il codice qui sopra genera un oggetto \emph{user} con le proprietà firstname, age e student. 
Per accedere alle proprietà dell'oggetto basta usare la notazione con il punto:
\begin{lstlisting}[style=JavaScriptCode]
console.log(user.firstname); \\prints "Paolo"
console.log(user.age); \\prints "23"
console.log(user.student); \\prints "true"
\end{lstlisting}
Lo stesso oggetto potrebbe essere creato utilizzando il costruttore \texttt{Object} di JavaScript
\begin{lstlisting}[style=JavaScriptCode]
var user = new object():
user.firstname = "Paolo";
user.age = 23;
user.student = true;
\end{lstlisting}
Come già detto, sebbene entrambe le definizioni siano accettate in JavaScript, in JSON è valida solo la seconda notazione, object literal.
\subsection{La sintassi JSON}
La sintassi di JSON non è altro che il miscuglio di object literal ed array literal per memorizzare dati e solo e soltanto rappresentarli.
Un esempio:
\begin{lstlisting}[style=JavaScriptCode]
[
{
"firstname": "Paolo",
"age": 23,
"student": true
},
{
"firstname": "Giuseppe",
"age": 40,
"student": false
}
]
\end{lstlisting}
La prima cosa da notare è che in questo documento non sono presenti variabili, così come punti e virgola.
In questo modo quando si trasmettono dei dati tramite HTTP ad un browser, il tutto avviene abbastanza velocemente grazie al numero ridotto di caratteri.

Oltre a questo, ci sono altri ovvi benefici nell'utilizzo di JSON come formato dati per la comunicazione in JavaScript: non bisogna preoccuparsi della valutazione dei dati, e quindi, è garantito un accesso più veloce alle informazioni che questo contiene.



\section{RESTful API}
Il significato dell’acronimo REST è REpresentational State Transfer, ossia una rappresentazione del trasferimento di stato di un determinato dato.

REST utilizza un modello client-server, dove il server è un server HTTP e il client invia richieste HTTP (GET, POST, PUT, DELETE), con un URL che al suo interno contiene i parametri codificati. L'URL descrive l'oggetto e il server genericamente risponde restituendo un'immagine, un documento HTML, un file CSV o qualunque altro tipo di dato.
Nel nostro caso il server risponde restituendo del codice e un JSON (JavaScript Object Notation).
Una RESTful API quindi è l'Interfaccia di Programmazione di un'Applicazione che usa le richieste HTTP per gestire i dati che vengono scambiati fra client e server.

Dato che in unicam-product-editor viene utilizzato lo stack MEAN, abbiamo scelto di utilizzare documenti JSON che risultano particolarmente adatti per la nostra applicazione, visto che tutti i nostri componenti sono in JavaScript e MongoDB\cite{mongodb} interagisce perfettamente con questo formato. 
Faremo degli esempi più dettagliati più avanti quando definiremo i nostri Data Model.

Le operazioni principali che si possono eseguire con questo metodo sono le seguenti:
\begin{itemize}
	\item\texttt{GET} per richiedere al server un determinato set di dati;
	\item\texttt{POST} per creare un nuovo documento all’interno del database;
	\item\texttt{PUT} per modificare o sostituire completamente un documento già esistente;
	\item\texttt{DELETE} per cancellare un documento contenuto all’interno del database al quale siamo collegati. 
\end{itemize}

Queste operazioni vengono spesso descritte attraverso l'acronimo CRUD, che sta per CREATE, READ, UPDATE e DELETE.
Il server HTTP, da parte sua, usa spesso assieme alle API REST dei codici di risposta; di seguito vengono elencati alcuni fra i più comuni:
\begin{itemize}
	\item 200 - “OK”
	\item 201 - “Created” (Utilizzato con POST)
	\item 400 - “Bad Request” (Ad esempio per l'assenza di parametri)
	\item 401 - “Unauthorized” (Non ci sono i parametri per l'autenticazione)
	\item 403 - “Forbidden” (L'utente è autenticato ma non ha i permessi)
	\item 404 - “Not Found”
\end{itemize}
Una descrizione completa è contenuta nell'apposito RFC 2616\cite{RFC2616}.

Lo sviluppo di API REST è alla base del nostro sviluppo, in quanto permette alla nostra applicazione di essere multipiattaforma. Per fare alcuni esempi di applicazioni di questo tipo si possono citare Google Docs, Pixlr o lo stesso Trello insieme ad Evernote. Le API REST permettono la facile implementazione dell'applicazione su molte piattaforme che potranno essere sviluppate in un secondo momento, trasformando il progetto iniziale in un progetto indipendente dalla piattaforma di partenza.

I dati da gestire nel nostro progetto si possono riassumere in questo modo:
\begin{itemize}
	\item Dati degli utenti
	\item Liste
	\item Oggetti
	\item Opzioni di ogni oggetto
	\item Parti di ogni opzione
\end{itemize}
Come potremo vedere a breve, diversamente dai tradizionali Database relazionali (in cui la forma principale di struttura dati è data dalle Tabelle), in MongoDB, essendo un Database NoSQL, e quindi non relazionale, non si parla di Tabelle, anche se il concetto di Database ad alto livello è lo stesso.

Nel Database MongoDB possono essere contenute più Collection, che possono forse essere paragonate alle Tabelle nei Database relazionali. A sua volta, ogni Collection conterrà uno o più Document, che a confronto con un Database relazionale corrisponde all'incirca alla riga di una Tabella. Ogni Document (così come ogni Collection) non segue però uno schema specifico come in una Tabella, ma può essere formato da una o più coppie chiave-valore, dove il contenuto può essere a sua volta una variabile semplice oppure qualcosa di più complicato come un array.

Il documento JSON appena preso in esempio rappresenta un utente nel nostro sistema. Ogni campo ha il suo specifico scopo, ma il campo più importante in un Document MongoDB è senza dubbio il campo \texttt{\_id}: questo rappresenta la chiave primaria di ogni Document. Quando un Document viene salvato senza questo campo, MongoDB ne assegna uno automaticamente, e con un valore univoco.

Ora passiamo ai vari Document che compongono le nostre Collection; la Collection degli Utenti conterrà Documenti di questo tipo:
\begin{lstlisting}[caption={User Collection}, style=javaScriptCode]
{
	"_id": {
		"$oid": "5894fa05f882a91c7c5cf0e6"
	},
	"displayName": "Paolo Andreassi",
	"email": "pablo15941@gmail.com",
	"password": "$2a$10$kyaJc1WP9KFvSVWzrPagLe.vgY76FjBQjwt76.HhC5u9oo96qoRo.",
	"__v": 0,
	"picture": "https://graph.facebook.com/v2.3/10209758034881202/...",
	"google": "106815394034042298036"
}
\end{lstlisting}
Si può notare l'importante presenza del campo \texttt{\_id}, così come gli altri dati utili al riconoscimento dell'utente. La password inoltre in unicam-product-editor non viene mai mostrata in chiaro all'interno del Database, anche se il campo ad essa corrispondente è presente e popolato. Questo è il risultato di una password impostata dall'utente ma successivamente encriptata con una funzione hash.
\newpage
Il Document di tipo Lista ha uno scopo puramente descrittivo nei confronti di ciò che contiene:
\begin{lstlisting}[caption={List Collection}, style=javaScriptCode]
{
"_id": {
"$oid": "589a30d1b2a4c717a8da16b3"
},
"nome": "Omino LEGO",
"__v": 0
}
\end{lstlisting}

La Collection degli Oggetti avrà dei Document in cui i campi \texttt{nome} e \texttt{descrizione} hanno una funzione descrittiva, ma oltre al campo \texttt{\_id} è presente il campo \texttt{\_list} che funge da collegamento con la Collection delle Liste: in questo campo infatti è indicato l'identificativo della Lista a cui appartiene uno specifico Oggetto:
\begin{lstlisting}[caption={Object Collection}, style=javaScriptCode]
{
"_id": {
"$oid": "589a38f93ec83413e4f010b2"
},
"nome": "Omino LEGO",
"descrizione": "LEGO figure",
"_list": [
"589a30d1b2a4c717a8da16b3"
],
"__v": 0
}
\end{lstlisting}

Essendo un Database con una struttura nidificata, anche i Document nelle Collection delle Parti e delle Opzioni avranno una struttura simile a quelli delle Collection degli Oggetti: anche in queste infatti è indicato il campo del Documento \emph{parente} a cui fanno riferimento:
\begin{lstlisting}[caption={Part Collection}, style=javaScriptCode]
{
"_id": {
"$oid": "589a3a2857ba982460b83fb7"
},
"nome": "Testa",
"_object": [
"589a38f93ec83413e4f010b2"
],
"__v": 0
}
\end{lstlisting}

La differenza più importante risiede nei Document che compongono la Collection delle Opzioni: in questi vengono indicati anche il campo \texttt{prezzo}, ma soprattutto il campo \texttt{forma}, che contiene una parte di URL con cui effettuare una chiamata REST API. Il campo forma, che viene mostrato all'utente nell'interfaccia della applicazione web, permette di visualizzare il file JSON relativo ad una forma 3D inserita tramite l'uploader e successivamente convertita nel formato usato da MongoDB e JavaScript:
\begin{lstlisting}[caption={Option Collection}, style=javaScriptCode]
{
"_id": {
"$oid": "589a3c5938319d1c8cb4e787"
},
"nome": "Testa Yoda",
"prezzo": 50,
"forma": "/shape/58593a6319290c09984a439b",
"_part": [
"589a3a2857ba982460b83fb7"
],
"__v": 0
}
\end{lstlisting}

Infine la Collection delle forme 3D convertite contiene l'insieme dei file JSON che rappresentano le stesse forme.

\section{Documentazione}
Una parte fondamentale della progettazione di API REST è la documentazione.
Per scrivere la documentazione necessaria è stato usato lo strumento Postman.

Postman\cite{postman} è un ambiente di sviluppo multipiattaforma utile per testare le API, ossia per eseguire una qualsiasi chiamata HTTP al nostro server, e monitorare la risposta ottenuta in modo chiaro e leggibile. 
Tramite questo strumento è possibile effettuare delle chiamate API senza dover mettere mano al codice dell’applicazione, consentendo di effettuare le chiamate tramite questo plugin che fornisce un’utile interfaccia grafica. Le richieste possono essere effettuate sia verso un server locale che verso un server online impostando tutti i dati di una tipica chiamata API, dagli headers al body.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.35]{Immagini/postman_ui.png}
	\caption{L'interfaccia utente di Postman}
\end{figure}

\section{NodeJS}
Node.js\cite{node} v4 è un interprete JavaScript orientato agli eventi, progettato per realizzare applicazioni di rete scalabili.
La caratteristica principale è che rimane inattivo finché non arriva una connessione in ingresso, o più generalmente un qualsiasi evento, e viene chiamata la relativa callback.
Questo paradigma è in contrasto con quello tradizionale basato sui thread.
Il principale vantaggio del paradigma ad eventi rispetto a quello basato sui thread si ha quando c'è un alto traffico.
In questo caso, infatti, l'alto numero di thread genera un alto overhead diminuendo drasticamente le prestazioni della macchina host.
Inoltre, dato che nessuna funzione di Node eseguirà direttamente operazioni di I/O, il processo non si bloccherà mai.

La versione di Node usata in unicam-product-editor è la v4.6.0.
Se da un lato su un server è normale avere solo una versione di Node, potrebbe non esserlo su una macchina di sviluppo.
Può capitare, infatti, che uno sviluppatore sia impegnato su più progetti Node che utilizzano versioni differenti.
Per risolvere questo problema possiamo installare NVM.
Node Version Manager permette di avere più versioni di Node contemporaneamente nel nostro sistema e fornisce una semplice CLI per poterle gestire.
In particolare, basta creare un file di testo chiamato \texttt{.nvmrc} in cui salvare il numero di versione di Node che si intende usare per la cartella corrente.
Poi, sarà sufficiente digitare il comando \texttt{nvm install} per scaricare ed utilizzare la giusta versione.

Node è disponibile per diverse piattaforme, come Linux, Microsoft Windows e Apple OS X.
Le applicazioni Node.js vengono costruite utilizzando librerie e moduli disponibili per l'ecosistema ed alcuni di essi sono stati utilizzati in unicam-product-editor.
Per iniziare ad utilizzare Node.js, dobbiamo per prima cosa creare un file \texttt{package.json}, che descrive la nostra applicazione ed elenca tutte le sue dipendenze.
NPM (Node.js Package Manager) installa una copia delle librerie in una sotto-cartella chiamata \texttt{node\_modules/}, della cartella principale dell'applicazione. 
Questo comporta diversi benefici, ad esempio isola le diverse versioni delle librerie, evitando così i problemi di compatibilità che si sarebbero presentati se avessimo installato tutto in una cartella standard come \texttt{/usr/lib}.

Il comando \texttt{npm install} creerà la cartella \texttt{node\_modules/}, con dentro tutte le librerie richieste e specificate nel file package.json:
\begin{lstlisting}[caption={package.json}, style=javaScriptCode][h]
{
	"name": "unicam-product-editor",
	"version": "1.0.0",
	"private": "true",
	"description": "Editor di prodotti 3D",
	"repository": "https://github.com/e-xtrategy/unicam-product-editor",
	"main": "app.js",
	"scripts": {
		"test": "nodemon --ignore tmp/ app.js",
		"start": "node app.js"
	},
	"author": "Paolo Andreassi",
	"license": "ISC",
	"dependencies": {
	...
	"async": "^2.1.4",
	"bcryptjs": "^2.4.0",
	"body-parser": "^1.15.2",
	...
	"cors": "^2.8.1",
	"express": "^4.14.0",
	"express-fileupload": "0.0.5",
	"express-handlebars": "^3.0.0",
	...
	"mongodb": "^2.2.10",
	"mongoose": "^4.7.8",
	...
	"python-shell": "^0.4.0",
	...
	"satellizer": "^0.15.5",
	...
	},
	"devDependencies": {
		"nodemon": "^1.11.0",
		"should": "~7.1.0",
		"supertest": "~1.1.0"
	},
		"engines": {
		"node": "4.6.0"
	}
}
\end{lstlisting}

E' interessante analizzare alcune parti di questo file, oltre al fatto che anche questo è in formato JSON, e oltre alle prime righe che descrivono il progetto in sé per sé.
Ci sono due script: quello chiamato \emph{start} avvia l'applicazione normalmente tramite il comando \texttt{node} seguito dal nome del file principale del server \texttt{app.js}.
Lo script chiamato \emph{test} invece è interessante, perché avvia uno strumento (installato tramite l'apposita dipendenza) chiamato nodemon. Questo utilissimo \emph{demone} fa sì che in fase di test ogni qual volta si verifichi un errore che interrompe l'esecuzione del server nodemon attende un salvataggio dei file del progetto, che indica che lo sviluppatore ha modificato il codice per correggere l'errore, e non appena questo evento si verifica il demone riavvia in automatico il server ricominciando ad eseguire il codice.

Un'altra dipendenza interessante riguarda \emph{python-shell}, che nel nostro progetto servirà ad eseguire lo script della libreria Three.js scritto in codice Python (altrimenti non eseguibile da Javascript), che si occupa di convertire il file .obj in JSON. python-shell può ricevere in input interi file scritti in Python per eseguirli in modo asincrono.

\section{Configurazione iniziale e Test}
Andiamo ora ad analizzare l'inizializzazione di un server Node.js, la configurazione di MongoDB su Mongolab e l'interazione di questi attraverso Express e Mongoose, che sono elementi che vedremo comunque più tardi.

Il primo comando che si utilizza per inizializzare il progetto e per creare il relativo file package.json è \texttt{npm init}. Il comando va lanciato dalla root del progetto, che sarà collegata al repository su GitHub.
Il prossimo passo consiste nel creare il file JavaScript del server in sé per sé. Questo file in unicam-product-editor si chiama \texttt{app.js}, ed è contenuto anch'esso nella root del progetto. Per eseguire già da ora il server, basterà posizionarsi con il prompt dei comandi nella root del progetto e lanciare il comando \texttt{node} seguito dal nome del file del server appena creato, quindi \texttt{node app.js}.

Si passa ora ad importare il framework express tramite la sua dipendenza e usando il gestore di pacchetti NPM. Per fare ciò dal prompt dei comandi basterà eseguire lo script \texttt{npm install express --save}. L'opzione \texttt{--save} serve a far comparire la dipendenza appena installata nell'apposita sezione del file package.json. Dalla versione 5.0.0 di NPM comunque questo comando è implicito.
Alla fine dell'esecuzione dello script, avremo la dipendenza installata localmente nella cartella \texttt{node\_modules/}, e il file package.json apparirà come segue:

\begin{lstlisting}[caption={test installazione express}, style=javaScriptCode]
{
	"name": "node server",
	"version": "1.0.0",
	"main": "app.js",
	"author": "Paolo Andreassi",
	"license": "ISC",
	"dependencies": {
	...
	"express": "^4.14.0",
	...
	}
}

\end{lstlisting}
Di conseguenza, andremo ad utilizzare express nel nostro file \texttt{app.js} come segue:
\begin{lstlisting}[caption={test require express}, style=javaScriptCode]
const express = require('express');
const app = express();
\end{lstlisting}
e lo utilizzeremo subito per creare il nostro server in ascolto sulla porta 3000 (almeno per questo test) tramite l'apposita istruzione
\begin{lstlisting}[caption={test server express}, style=javaScriptCode]
app.listen(3000, function() {
	console.log('listening on port 3000')
})
\end{lstlisting}
In express possiamo gestire le richieste HTTP GET attraverso il metodo \texttt{get}:
\begin{lstlisting}[style=javaScriptCode]
app.get(path, callback)
\end{lstlisting}
che useremo così per la nostra configurazione di test
\begin{lstlisting}[caption={test hello world}, style=javaScriptCode]
app.get('/', function(req, res) {
	res.send('Hello World')
})
\end{lstlisting}
In questo modo aprendo il nostro browser e digitando \texttt{localhost:3000} nella barra URL, dopo esserci assicurati di aver avviato l'applicazione, quello che il nostro server risponderà alla richiesta HTTP GET sarà:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.8]{Immagini/test_hello_world.png}
	\caption{Test di una richiesta HTTP GET}
\end{figure}

Una volta configurato il server per questo test, andiamo a fare lo stesso per il nostro database MongoDB.
In unicam-product-editor il database è ospitato in cloud attraverso il servizio mLab, che a sua volta si appoggia a servizi cloud quali Amazon Web Services, Google Cloud Platform e Windows Azure. mLab offre diversi piani tariffari, ma per il nostro progetto il piano Sandbox che offre 0.5GB di spazio gratuito va più che bene. Una volta creato il database su mLab, e dopo aver creato un utente di tipo amministratore per lo stesso database, mLab creerà una indirizzo URL, detto MongoDB URI, utilizzabile per connettersi a questo servizio, mediante l'uso del nome utente e della password dell'account amministratore. 
\newpage
La stringa corrispondente al database di unicam-product-editor è la seguente:
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.5]{Immagini/mongodb_uri.png}
	\caption{MongoDB URI}
\end{figure}

Come si può notare dalla schermata qui sopra, oltre ad essere indicata la versione del database in uso, è presente anche il comando da utilizzare per connettersi a mLab tramite il mongo shell, ossia un'interfaccia interattiva di MongoDB, che usa anch'essa istruzioni in JavaScript.
Il prossimo step consiste nell'utilizzare proprio questo MongoDB URI per connettersi al database. In questo caso di test useremo il client nativo mongodb, mentre in unicam-product-editor verrà utilizzata la libreria Mongoose, che vedremo più tardi.

Per installare il client mongodb basta lanciare il comando \texttt{npm install mongodb}, e per poterlo usare nel nostro progetto bisognerà importarlo come già fatto per Express, ossia tramite l'istruzione
\begin{lstlisting}[style=javaScriptCode]
const MongoClient = require('mongodb').MongoClient
\end{lstlisting}
L'istruzione standard in Express per la connessione al database tramite il client mongodb è la seguente:
\begin{lstlisting}[style=javaScriptCode]
MongoClient.connect('MONGODB_URI', function(err, client){
	...
})
\end{lstlisting}
e utilizzeremo la callback della funzione \texttt{.connect} per avviare il server Node.js solamente una volta che sarà avvenuta la corretta connessione al database. Per fare ciò basta aggiungere il codice
\begin{lstlisting}[caption={connessione a mongodb}, style=javaScriptCode]
MongoClient.connect('MONGODB_URI', function(err, client){
	if (err) return console.log(err)
	db = client.db('unicam-product-editor')
	app.listen(3000, function() {
		console.log('listening on port 3000')
	})
})
\end{lstlisting}
utilizzando la variabile db per salvare la sessione di collegamento al database appena ottenuta.

A questo punto la connessione al nostro database è pronta all'uso, e possiamo utilizzare la funzione \texttt{.collection} per gestire le Collection presenti nel database.
Se volessimo ad esempio inserire un Document in una Collection del database unicam-product-editor, la sintassi sarebbe la seguente:
\begin{lstlisting}[caption={mongodb save}, style=javaScriptCode]
db.collection('COLLECTION').save('DOCUMENT', function(err, result){
	if (err) return console.log(err) //in caso di errore

	console.log('saved to database') //in caso di corretto salvataggio
})
\end{lstlisting}

\section{Express}
Con express.js\cite{express}, noi abbiamo creato la vera e propria "applicazione", che ascolta le richieste HTTP in ingresso su una data porta. Quando arriva una richiesta, questa passa attraverso una catena di intermediari, detti \emph{middleware}.
Ogni nodo della catena è definito da un req (request) object, usato per ricevere dei parametri, e un res (results) object, usato per salvare i risultati. 
Ogni nodo può decidere se eseguire delle operazioni, o se passare i due oggetti al nodo successivo. 
Per aggiungere un nuovo middleware usiamo la funzione \texttt{app.use()}. 
Il middleware principale, chiamato “router”, analizza l’URL e il tipo di richiesta per poterla poi indirizzare verso una specifica funzione.

Il codice della nostra applicazione apparirà così organizzato, visto che i vari handler e le diverse funzioni specifiche saranno poi distribuiti in file separati.

\begin{lstlisting}[caption={app.js}, style=javaScriptCode]
var path = require('path'),
	qs = require('querystring'),

	async = require('async'),
	bcrypt = require('bcryptjs'),
	bodyParser = require('body-parser'),
	colors = require('colors'),
	cors = require('cors'),
	express = require('express'),
	exphbs = require('express-handlebars'),
	favicon = require('serve-favicon'),
	fileUpload = require('express-fileupload'),
	fs = require('fs'),
	http = require('http'),
	logger = require('morgan'),
	jwt = require('jwt-simple'),
	moment = require('moment'),
	mongoose = require('mongoose'),
	request = require('request'),
	url = require('url'),
	
	upload       = require('./app/upload'),
	convert      = require('./app/convert'),
	converted    = require('./app/converted'),
	readjsonfile = require('./app/readjsonfile'),
	users        = require('./routes/users'),
	getshapes    = require('./app/getshapes'),
	config       = require('./config');
	
var app = express();
app.set('port', process.env.NODE_PORT || 3000);
app.set('host', process.env.NODE_IP || 'localhost');
app.set('view engine', 'handlebars');
app.engine('handlebars', exphbs({defaultLayout: 'main'}));
app.use(bodyParser.json());
app.use('/static', express.static('public'));
app.use(express.static('partials'));
app.use(fileUpload());
require('./app/schema'),
require('./routes')(app);
\end{lstlisting}

e la route principale del progetto sarà così dichiarata, essendo Handlebars il motore di rendering utilizzato in unicam-product-editor:

\begin{lstlisting}[caption={configurazione server}, style=javaScriptCode]
app.get('/', function(req, res) {
	res.render('layouts/main.handlebars');
})
\end{lstlisting}

Handlebars.js è un'estensione del linguaggio di template \emph{Mustache}, creato da Chris Wanstrath. Sia Handlebars.js che Mustache sono linguaggi di template \emph{logicless}, che tengono separate, come da convenzione, la parte visiva del progetto e la parte di codice, migliorando l'organizzazione del progetto stesso.

Per ultimo definiamo il nostro server in ascolto sulla porta indicata con la funzione Express \texttt{app.set(port)}, o sulla porta 3000 in tutti gli altri casi.
\begin{lstlisting}[caption={configurazione server}, style=javaScriptCode]
server = app.listen(process.env.PORT || 3000, function() {
	var port = server.address().port
	console.log("Express server listening on port %s", port)
})
\end{lstlisting}

\section{Mongoose}
A questo punto, i nostri dati vanno gestiti tramite l'uso di Mongoose, un modellatore di oggetti MongoDB progettato per l'uso in Node.js.
Come detto in precedenza, le Collection da definire sono le seguenti:
\begin{itemize}
	\item Users
	\item Lists
	\item Objects
	\item Parts
	\item Shapes
\end{itemize}

Per fare ciò, bisogna definire uno schema per ognuna delle Collection appena esposte; partendo dal primo, lo UserSchema sarà così dichiarato:

\begin{lstlisting}[caption={userSchema}, style=javaScriptCode]
var userSchema = new mongoose.Schema({
	email: { type: String, unique: true, lowercase: true },
	password: { type: String, select: false },
	displayName: String,
	picture: String,
	facebook: String,
	google: String
});
\end{lstlisting}

come possiamo notare, con mongoose e MongoDB è possibile non solo dichiarare il tipo di dato che ogni proprietà conterrà, ma anche dei vincoli attraverso l'uso dei trim.
Inoltre con mongoose è possibile definire, all'interno dello userSchema, funzioni e metodi che potremo all'occorrenza richiamare da altre parti del progetto.

\begin{lstlisting}[caption={userSchema}, style=javaScriptCode]
userSchema.pre('save', function(next) {
	var user = this;
	if (!user.isModified('password')) {
		return next();
	}
	bcrypt.genSalt(10, function(err, salt) {
		bcrypt.hash(user.password, salt, function(err, hash) {
			user.password = hash;
			next();
		});
	});
});

userSchema.methods.comparePassword = function(password, done) {
	bcrypt.compare(password, this.password, function(err, isMatch) {
		done(err, isMatch);
	});
};
\end{lstlisting}

La funzione \texttt{userSchema.pre} viene eseguita appena prima dell'inserimento di un nuovo utente (tramite la funzione save) e si assicura di encriptare nuovamente la password di un utente ogni qual volta questa venga cambiata, prima di inserirla nel database.
Il metodo \texttt{.comparePassword} invece si avvale dell'uso della libreria \emph{bcrypt} per decriptare la password passata al metodo come parametro prima di confrontarla con la password presente nel database, anch'essa opportunamente decriptata.

Gli altri schema sono stati dichiarati nell'apposito file \texttt{schema.js}, ad eccezione della Collection Shape che non ha bisogno di un vero e proprio schema, e appaiono in questo modo:

\begin{lstlisting}[caption={/app/schema.js}, style=javaScriptCode]
var mongoose = require('mongoose'),
Schema = mongoose.Schema;

var lists = Schema({
nome        : String
});

var objects = Schema({
_list       : [{type: String, ref: 'List'}],
nome        : String,
descrizione : String,
parts       : [{type: Schema.Types.ObjectId, ref: 'Part'}]
});

var parts = Schema({
_object     : [{type: String, ref: 'Object'}],
nome        : String,
options     : [{type: Schema.Types.ObjectId, ref: 'Option'}]
});

var options = Schema({
_part       : [{type: String, ref: 'Part'}],
nome        : String,
prezzo      : Number,
forma       : String
});

module.exports    = mongoose.model('Option', options);
module.exports    = mongoose.model('Part', parts);
module.exports    = mongoose.model('Object', objects);
module.exports    = mongoose.model('List', lists);
\end{lstlisting}

E' interessante notare come i vari schema si possono collegare tra loro attraverso l'uso del trim \texttt{ref}, che punta al nome di uno schema esportato.
Nel caso di unicam-product-editor, che ha una struttura dati nidificata, questo trim è di cruciale importanza.

In mongoose alcuni dei principali metodi usati per l'interfacciamento con il database sono:
\begin{itemize}
	\item \texttt{find()} per trovare tutti i Document all'interno di una Collection;
	\item \texttt{findById()} per trovare un Document a seconda del suo attributo \texttt{\_id};
	\item \texttt{findOne()} per trovare il primo Document che rispetti le condizioni dichiarate;
	\item \texttt{deleteOne()} per eliminare il primo Document che rispetti le condizioni dichiarate;
	\item \texttt{updateOne()} per aggiornare il primo Document che rispetti le condizioni dichiarate;
	\item \texttt{replaceOne()} simile a \texttt{updateOne()}, con la differenza che mongoose rimpiazzerà il Document esistente con il Document che si darà in input.
\end{itemize}

\section{Heroku}
Heroku\cite{heroku} è un platform as a service (PaaS) sul cloud che supporta linguaggi di programmazione come JavaScript(quindi Node.js), Ruby, Python, Java, PHP ed altri.
Il fatto che sia un PaaS vuol dire che Heroku mette a disposizione di chi sviluppa una piattaforma dove poter rilasciare rapidamente una applicazione senza dover conoscere come configurare l’infrastruttura che c’è dietro.
Nel nostro caso, Heroku ci è utile per rilasciare unicam-product-editor come web app su un servizio apposito.

Per la configurazione e il rilascio della applicazione su Heroku, bisgona prima di tutto installare il suo CLI (Command Line Interface) e dopo essersi autenticati al servizio Heroku si procede a creare un clone del repository di unicam-product-editor presente su GitHub attraverso il comando \texttt{git clone 'git repository'}:

\begin{lstlisting}[style=javaScriptCode]
$ git clone https://github.com/e-xtrategy/unicam-product-editor.git
\end{lstlisting}

A questo punto, non resta che creare una nuova \emph{commit}, ma invece che eseguire un \emph{push} sul repository originale, si fa lo stesso utilizzando il comando \texttt{git push heroku master}.
Alla fine dell'operazione, in caso di successo, il CLI mostra l'URL su cui è ospitata la nostra applicazione.
Di seguito uno screenshot delle operazioni appena descritte eseguite in sequenza.
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.7]{Immagini/heroku_initialize.png}
	\caption{Inizializzazione di unicam-product-editor su Heroku}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[scale=0.8]{Immagini/heroku_deployment.png}
	\caption{Rilascio di unicam-product-editor su Heroku}
\end{figure}